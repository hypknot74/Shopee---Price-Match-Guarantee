{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-04-21T05:05:59.395556Z",
     "iopub.status.busy": "2021-04-21T05:05:59.394969Z",
     "iopub.status.idle": "2021-04-21T05:06:09.468275Z",
     "shell.execute_reply": "2021-04-21T05:06:09.467575Z"
    },
    "papermill": {
     "duration": 10.083243,
     "end_time": "2021-04-21T05:06:09.468460",
     "exception": false,
     "start_time": "2021-04-21T05:05:59.385217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import math\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, GroupKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import cudf\n",
    "import cuml\n",
    "from cuml.feature_extraction.text import TfidfVectorizer\n",
    "from cuml import PCA\n",
    "from joblib import dump, load\n",
    "import gc\n",
    "\n",
    "\n",
    "# Amount of tf records we want to create\n",
    "FOLDS = 15\n",
    "# Random seed for stratification\n",
    "SEED = 123\n",
    "# Image size \n",
    "IMAGE_SIZE = (512, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-21T05:06:09.482006Z",
     "iopub.status.busy": "2021-04-21T05:06:09.476559Z",
     "iopub.status.idle": "2021-04-21T05:28:12.534275Z",
     "shell.execute_reply": "2021-04-21T05:28:12.533626Z"
    },
    "papermill": {
     "duration": 1323.06298,
     "end_time": "2021-04-21T05:28:12.534452",
     "exception": false,
     "start_time": "2021-04-21T05:06:09.471472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/cudf/core/join/join.py:368: UserWarning: can't safely cast column from right with type int32 to uint16, upcasting to int32\n",
      "  \"right\", dtype_r, dtype_l, libcudf_join_type\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our title text embedding shape is (68500, 5000)\n",
      "Using the same posting id as prediction our f1 score is 0.46084817913674353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:668: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=15.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "Writing TFRecord 0 of 14...\n",
      "0 , 100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , 1600 , 1700 , 1800 , 1900 , 2000 , 2100 , 2200 , 2300 , 2400 , 2500 , 2600 , 2700 , 2800 , 2900 , 3000 , 3100 , 3200 , 3300 , 3400 , 3500 , 3600 , 3700 , 3800 , 3900 , 4000 , 4100 , 4200 , 4300 , 4400 , 4500 , \n",
      "\n",
      "--------------------------------------------------\n",
      "Writing TFRecord 1 of 14...\n",
      "0 , 100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , 1600 , 1700 , 1800 , 1900 , 2000 , 2100 , 2200 , 2300 , 2400 , 2500 , 2600 , 2700 , 2800 , 2900 , 3000 , 3100 , 3200 , 3300 , 3400 , 3500 , 3600 , 3700 , 3800 , 3900 , 4000 , 4100 , 4200 , 4300 , 4400 , 4500 , \n",
      "\n",
      "--------------------------------------------------\n",
      "Writing TFRecord 2 of 14...\n",
      "0 , 100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , 1600 , 1700 , 1800 , 1900 , 2000 , 2100 , 2200 , 2300 , 2400 , 2500 , 2600 , 2700 , 2800 , 2900 , 3000 , 3100 , 3200 , 3300 , 3400 , 3500 , 3600 , 3700 , 3800 , 3900 , 4000 , 4100 , 4200 , 4300 , 4400 , 4500 , \n",
      "\n",
      "--------------------------------------------------\n",
      "Writing TFRecord 3 of 14...\n",
      "0 , 100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , 1600 , 1700 , 1800 , 1900 , 2000 , 2100 , 2200 , 2300 , 2400 , 2500 , 2600 , 2700 , 2800 , 2900 , 3000 , 3100 , 3200 , 3300 , 3400 , 3500 , 3600 , 3700 , 3800 , 3900 , 4000 , 4100 , 4200 , 4300 , 4400 , 4500 , \n",
      "\n",
      "--------------------------------------------------\n",
      "Writing TFRecord 4 of 14...\n",
      "0 , 100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , 1600 , 1700 , 1800 , 1900 , 2000 , 2100 , 2200 , 2300 , 2400 , 2500 , 2600 , 2700 , 2800 , 2900 , 3000 , 3100 , 3200 , 3300 , 3400 , 3500 , 3600 , 3700 , 3800 , 3900 , 4000 , 4100 , 4200 , 4300 , 4400 , 4500 , \n",
      "\n",
      "--------------------------------------------------\n",
      "Writing TFRecord 5 of 14...\n",
      "0 , 100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , 1600 , 1700 , 1800 , 1900 , 2000 , 2100 , 2200 , 2300 , 2400 , 2500 , 2600 , 2700 , 2800 , 2900 , 3000 , 3100 , 3200 , 3300 , 3400 , 3500 , 3600 , 3700 , 3800 , 3900 , 4000 , 4100 , 4200 , 4300 , 4400 , 4500 , \n",
      "\n",
      "--------------------------------------------------\n",
      "Writing TFRecord 6 of 14...\n",
      "0 , 100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , 1600 , 1700 , 1800 , 1900 , 2000 , 2100 , 2200 , 2300 , 2400 , 2500 , 2600 , 2700 , 2800 , 2900 , 3000 , 3100 , 3200 , 3300 , 3400 , 3500 , 3600 , 3700 , 3800 , 3900 , 4000 , 4100 , 4200 , 4300 , 4400 , 4500 , \n",
      "\n",
      "--------------------------------------------------\n",
      "Writing TFRecord 7 of 14...\n",
      "0 , 100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , 1600 , 1700 , 1800 , 1900 , 2000 , 2100 , 2200 , 2300 , 2400 , 2500 , 2600 , 2700 , 2800 , 2900 , 3000 , 3100 , 3200 , 3300 , 3400 , 3500 , 3600 , 3700 , 3800 , 3900 , 4000 , 4100 , 4200 , 4300 , 4400 , 4500 , \n",
      "\n",
      "--------------------------------------------------\n",
      "Writing TFRecord 8 of 14...\n",
      "0 , 100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , 1600 , 1700 , 1800 , 1900 , 2000 , 2100 , 2200 , 2300 , 2400 , 2500 , 2600 , 2700 , 2800 , 2900 , 3000 , 3100 , 3200 , 3300 , 3400 , 3500 , 3600 , 3700 , 3800 , 3900 , 4000 , 4100 , 4200 , 4300 , 4400 , 4500 , \n",
      "\n",
      "--------------------------------------------------\n",
      "Writing TFRecord 9 of 14...\n",
      "0 , 100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , 1600 , 1700 , 1800 , 1900 , 2000 , 2100 , 2200 , 2300 , 2400 , 2500 , 2600 , 2700 , 2800 , 2900 , 3000 , 3100 , 3200 , 3300 , 3400 , 3500 , 3600 , 3700 , 3800 , 3900 , 4000 , 4100 , 4200 , 4300 , 4400 , 4500 , \n",
      "\n",
      "--------------------------------------------------\n",
      "Writing TFRecord 10 of 14...\n",
      "0 , 100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , 1600 , 1700 , 1800 , 1900 , 2000 , 2100 , 2200 , 2300 , 2400 , 2500 , 2600 , 2700 , 2800 , 2900 , 3000 , 3100 , 3200 , 3300 , 3400 , 3500 , 3600 , 3700 , 3800 , 3900 , 4000 , 4100 , 4200 , 4300 , 4400 , 4500 , \n",
      "\n",
      "--------------------------------------------------\n",
      "Writing TFRecord 11 of 14...\n",
      "0 , 100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , 1600 , 1700 , 1800 , 1900 , 2000 , 2100 , 2200 , 2300 , 2400 , 2500 , 2600 , 2700 , 2800 , 2900 , 3000 , 3100 , 3200 , 3300 , 3400 , 3500 , 3600 , 3700 , 3800 , 3900 , 4000 , 4100 , 4200 , 4300 , 4400 , 4500 , \n",
      "\n",
      "--------------------------------------------------\n",
      "Writing TFRecord 12 of 14...\n",
      "0 , 100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , 1600 , 1700 , 1800 , 1900 , 2000 , 2100 , 2200 , 2300 , 2400 , 2500 , 2600 , 2700 , 2800 , 2900 , 3000 , 3100 , 3200 , 3300 , 3400 , 3500 , 3600 , 3700 , 3800 , 3900 , 4000 , 4100 , 4200 , 4300 , 4400 , 4500 , \n",
      "\n",
      "--------------------------------------------------\n",
      "Writing TFRecord 13 of 14...\n",
      "0 , 100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , 1600 , 1700 , 1800 , 1900 , 2000 , 2100 , 2200 , 2300 , 2400 , 2500 , 2600 , 2700 , 2800 , 2900 , 3000 , 3100 , 3200 , 3300 , 3400 , 3500 , 3600 , 3700 , 3800 , 3900 , 4000 , 4100 , 4200 , 4300 , 4400 , 4500 , \n",
      "\n",
      "--------------------------------------------------\n",
      "Writing TFRecord 14 of 14...\n",
      "0 , 100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , 1600 , 1700 , 1800 , 1900 , 2000 , 2100 , 2200 , 2300 , 2400 , 2500 , 2600 , 2700 , 2800 , 2900 , 3000 , 3100 , 3200 , 3300 , 3400 , 3500 , 3600 , 3700 , 3800 , 3900 , 4000 , 4100 , 4200 , 4300 , 4400 , 4500 , "
     ]
    }
   ],
   "source": [
    "# Function to get our f1 score\n",
    "def f1_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    len_y_pred = y_pred.apply(lambda x: len(x)).values\n",
    "    len_y_true = y_true.apply(lambda x: len(x)).values\n",
    "    f1 = 2 * intersection / (len_y_pred + len_y_true)\n",
    "    return f1\n",
    "\n",
    "# Function to get our text title embeddings (we also use pca to reduce the dimension)\n",
    "def get_text_embeddings(df_cu, max_features = 15000, n_components = 5000):\n",
    "    model = TfidfVectorizer(stop_words = 'english', binary = True, max_features = max_features)\n",
    "    text_embeddings = model.fit_transform(df_cu['title']).toarray()\n",
    "    # Save tfidf model to disk for inference\n",
    "    dump(model, 'TfidfVectorizer.joblib')\n",
    "    # Sanity Check\n",
    "    model = load('TfidfVectorizer.joblib')\n",
    "    # Save pca model to disk for inference\n",
    "    pca = PCA(n_components = n_components)\n",
    "    text_embeddings = pca.fit_transform(text_embeddings).get()\n",
    "    dump(pca, 'PCA.joblib')\n",
    "    print(f'Our title text embedding shape is {text_embeddings.shape}')\n",
    "    del model, pca\n",
    "    gc.collect()\n",
    "    return text_embeddings\n",
    "\n",
    "# Function to read and preprocess our data\n",
    "def preprocess():\n",
    "    # Read train and test csv\n",
    "    train = pd.read_csv('../input/shoee-augmented-data/shopee_augmented_data/train.csv')\n",
    "    test = pd.read_csv('../input/shoee-augmented-data/shopee_augmented_data/test.csv')\n",
    "    label_mapper = dict(zip(train['label_group'].unique(), np.arange(len(train['label_group'].unique()))))\n",
    "    train['label_group'] = train['label_group'].map(label_mapper)\n",
    "    # Get ground truth labels format\n",
    "    tmp = train.groupby(['label_group'])['posting_id'].unique().to_dict()\n",
    "    train['matches'] = train['label_group'].map(tmp)\n",
    "    train['matches'] = train['matches'].apply(lambda x: ' '.join(x))\n",
    "    # Calculate title features with tfidf\n",
    "    train_cu = cudf.DataFrame(train)\n",
    "    text_embeddings = get_text_embeddings(train_cu)\n",
    "    # Calculate naive score using self-post\n",
    "    train['f1'] = f1_score(train['matches'], train['posting_id'])\n",
    "    score = train['f1'].mean()\n",
    "    print(f'Using the same posting id as prediction our f1 score is {score}')\n",
    "    return train, text_embeddings\n",
    "\n",
    "train, text_embeddings = preprocess()\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = FOLDS, shuffle = True, random_state = SEED)\n",
    "for fold, (trn_ind, val_ind) in enumerate(kfold.split(train, train['label_group'])):\n",
    "    train.loc[val_ind, 'fold'] = fold\n",
    "train['fold'] = train['fold'].astype(int)\n",
    "\n",
    "# Save train\n",
    "train.to_csv('train_folds.csv', index = False)\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _float_feature(value):\n",
    "    \"\"\"Returns a float_list from a float / double.\"\"\"\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def serialize_array(array):\n",
    "    tensor = tf.convert_to_tensor(array)\n",
    "    result = tf.io.serialize_tensor(tensor)\n",
    "    return result\n",
    "\n",
    "def serialize_example(posting_id, image, title, label_group, matches):\n",
    "    feature = {\n",
    "        'posting_id': _bytes_feature(posting_id),\n",
    "        'image': _bytes_feature(image),\n",
    "        'title': _bytes_feature(title),\n",
    "        'label_group': _int64_feature(label_group),\n",
    "        'matches': _bytes_feature(matches)\n",
    "    }\n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example_proto.SerializeToString()\n",
    "\n",
    "\n",
    "for fold in range(FOLDS):\n",
    "    print('\\n')\n",
    "    print('-'*50)\n",
    "    print(f'Writing TFRecord {fold} of {FOLDS - 1}...')\n",
    "    train_ = train[train['fold'] == fold]\n",
    "    # Get indices to slice our text features\n",
    "    text_embeddings_ = text_embeddings[train_.index]\n",
    "    with tf.io.TFRecordWriter('train%.2i-%i.tfrec'%(fold, train_.shape[0])) as writer:\n",
    "        for k in range(train_.shape[0]):\n",
    "            row = train_.iloc[k]\n",
    "            image = cv2.imread('../input/shoee-augmented-data/shopee_augmented_data/train_images/' + row['image'])\n",
    "            image = cv2.resize(image, IMAGE_SIZE)\n",
    "            image = cv2.imencode('.jpg', image, (cv2.IMWRITE_JPEG_QUALITY, 100))[1].tobytes()\n",
    "            title = text_embeddings_[k].astype(np.float64)\n",
    "            title = serialize_array(title)\n",
    "            posting_id = row['posting_id']\n",
    "            label_group = row['label_group']\n",
    "            matches = row['matches']\n",
    "            example = serialize_example(str.encode(posting_id),\n",
    "                                        image,\n",
    "                                        title,\n",
    "                                        label_group,\n",
    "                                        str.encode(matches))\n",
    "            writer.write(example)\n",
    "            if k%100==0: print(k,', ',end='')\n",
    "                \n",
    "\n",
    "# Save csv\n",
    "train.to_csv('train_folds.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1340.64833,
   "end_time": "2021-04-21T05:28:14.759696",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-21T05:05:54.111366",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
